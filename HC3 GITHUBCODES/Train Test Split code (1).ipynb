{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60c63ddd-b7be-4b4a-8b56-e4e5dc55a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c7e1511-e864-495b-b7a5-0446fcbbfe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2= pd.read_csv('/home/yadagiri/updated dataset.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03068184-9e30-4a88-8a93-a43bcae0db82",
   "metadata": {},
   "source": [
    "Train and Split the DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f606c0b-4395-4cb6-bcba-34748c08b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your CSV dataset into a DataFrame\n",
    "df = pd.read_csv(\"/home/yadagiri/Downloads/HC3 DATASET FILES/Hc3Finalfeatures (3).csv\")\n",
    "\n",
    "# Define the label column\n",
    "label_column = 'label'  # Replace 'label_column_name' with the actual name of your label column\n",
    "\n",
    "# Separate the data based on labels\n",
    "label_0_data = df[df[label_column] == 0]\n",
    "label_1_data = df[df[label_column] == 1]\n",
    "\n",
    "# Split the data for each label\n",
    "label_0_train, label_0_test = train_test_split(label_0_data, test_size=0.2, random_state=42)\n",
    "label_1_train, label_1_test = train_test_split(label_1_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Concatenate the training and testing sets for each label\n",
    "train_data = pd.concat([label_0_train, label_1_train])\n",
    "test_data = pd.concat([label_0_test, label_1_test])\n",
    "\n",
    "# Shuffle the data (optional)\n",
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_data = test_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Calculate the number of '0's required in the train and test sets\n",
    "required_label_0_train_count = int(len(df) * 0.0715 * 0.8)\n",
    "required_label_0_test_count = int(len(df) * 0.0715 * 0.2)\n",
    "\n",
    "# Subset the train and test sets to maintain the required percentage of '0's\n",
    "train_data_label_0 = train_data[train_data[label_column] == 0].head(required_label_0_train_count)\n",
    "train_data_label_1 = train_data[train_data[label_column] == 1]\n",
    "test_data_label_0 = test_data[test_data[label_column] == 0].head(required_label_0_test_count)\n",
    "test_data_label_1 = test_data[test_data[label_column] == 1]\n",
    "\n",
    "# Concatenate the subsets\n",
    "final_train_data = pd.concat([train_data_label_0, train_data_label_1])\n",
    "final_test_data = pd.concat([test_data_label_0, test_data_label_1])\n",
    "\n",
    "# Shuffle the final data (optional)\n",
    "final_train_data = final_train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "final_test_data = final_test_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the training and testing sets to CSV files\n",
    "final_train_data.to_csv(\"/home/yadagiri/HC3train_dataset.csv\", index=False)\n",
    "final_test_data.to_csv(\"/home/yadagiri/HC3test_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b762fe-a8bf-4164-ac55-62273b981fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d127ab-cfb0-4373-8d28-bb54b448aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT THE LABEL WISE NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77e0a42f-b256-466f-9ca7-57841dbbb8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2782"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_label_0_train_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d89c0c-c5ba-4f1b-9cfb-699ab4f9f2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_label_0_test_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c569953-e761-4fb4-a649-20c2056610a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c899e660-a0b2-4a37-98ac-0b83aafcccdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: label\n",
      "0    19458\n",
      "1    19458\n",
      "Name: count, dtype: int64\n",
      "Test set: label\n",
      "0    4864\n",
      "1    4864\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your CSV dataset into a DataFrame\n",
    "df = pd.read_csv(\"/home/yadagiri/Downloads/HC3 DATASET FILES/Hc3Finalfeatures (3).csv\")\n",
    "\n",
    "# Define the label column\n",
    "label_column = 'label'  # Replace 'label_column_name' with the actual name of your label column\n",
    "\n",
    "\n",
    "# Separate the dataset based on labels\n",
    "df_label_0 = df[df['label'] == 0]\n",
    "df_label_1 = df[df['label'] == 1]\n",
    "\n",
    "# Shuffle the data\n",
    "df_label_0 = df_label_0.sample(frac=1).reset_index(drop=True)\n",
    "df_label_1 = df_label_1.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Calculate the number of samples needed for each label in the test set\n",
    "n_samples = int(0.2 * len(df) / 2)\n",
    "\n",
    "# Split the data\n",
    "test_label_0 = df_label_0.iloc[:n_samples]\n",
    "train_label_0 = df_label_0.iloc[n_samples:]\n",
    "\n",
    "test_label_1 = df_label_1.iloc[:n_samples]\n",
    "train_label_1 = df_label_1.iloc[n_samples:]\n",
    "\n",
    "# Combine the splits\n",
    "train_set = pd.concat([train_label_0, train_label_1]).sample(frac=1).reset_index(drop=True)\n",
    "test_set = pd.concat([test_label_0, test_label_1]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Verify the splits\n",
    "print(f\"Train set: {train_set['label'].value_counts()}\")\n",
    "print(f\"Test set: {test_set['label'].value_counts()}\")\n",
    "\n",
    "# Save the splits\n",
    "train_set.to_csv(\"/home/yadagiri/HC3train_dataset1.csv\", index=False)\n",
    "test_set.to_csv(\"/home/yadagiri/HC3test_dataset1.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8438742-f7f6-4dde-9675-de1ced3c2a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: label\n",
      "1    19458\n",
      "0    19458\n",
      "Name: count, dtype: int64\n",
      "Test set: label\n",
      "1    4864\n",
      "0    4864\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your CSV dataset into a DataFrame\n",
    "df = pd.read_csv(\"/home/yadagiri/Downloads/HC3 DATASET FILES/Hc3Finalfeatures (3).csv\")\n",
    "\n",
    "# Define the label column\n",
    "label_column = 'label'  # Replace 'label_column_name' with the actual name of your label column\n",
    "\n",
    "\n",
    "# Separate the dataset based on labels\n",
    "df_label_0 = df[df['label'] == 0]\n",
    "df_label_1 = df[df['label'] == 1]\n",
    "\n",
    "# Shuffle the data\n",
    "df_label_0 = df_label_0.sample(frac=1).reset_index(drop=True)\n",
    "df_label_1 = df_label_1.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Calculate the number of samples needed for each label in the test set\n",
    "n_samples = int(0.2 * len(df) / 2)\n",
    "\n",
    "# Split the data\n",
    "test_label_0 = df_label_0.iloc[:n_samples]\n",
    "train_label_0 = df_label_0.iloc[n_samples:]\n",
    "\n",
    "test_label_1 = df_label_1.iloc[:n_samples]\n",
    "train_label_1 = df_label_1.iloc[n_samples:]\n",
    "\n",
    "# Combine the splits\n",
    "train_set = pd.concat([train_label_0, train_label_1]).sample(frac=1).reset_index(drop=True)\n",
    "test_set = pd.concat([test_label_0, test_label_1]).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Verify the splits\n",
    "print(f\"Train set: {train_set['label'].value_counts()}\")\n",
    "print(f\"Test set: {test_set['label'].value_counts()}\")\n",
    "\n",
    "# Save the splits\n",
    "train_set.to_csv(\"/home/yadagiri/HC3train_dataset5.csv\", index=False)\n",
    "test_set.to_csv(\"/home/yadagiri/HC3test_dataset5.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c9cc6c-716e-463e-8413-156121eecdca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
